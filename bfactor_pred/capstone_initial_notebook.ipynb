{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <div align=\"left\"> üß¨ Capstone: b-factor prediction for alphaFold structures for epitope prediction </div>\n",
        "\n",
        "<img src=\"https://userguide.mdanalysis.org/stable/_images/rmsf-view.gif\" height=\"256\" align=\"right\" style=\"height:256px\">\n",
        "\n",
        "#### Our goal is to leverage AlphaFold2 to improve epitope predictions beyond sequence-based methods through considering structural constraints on antigen processing, similar to the referenced paper.\n",
        "\n",
        "\n",
        "<div align=\"left\">\n",
        "  <h3> üìÅ Google Drive </h3>\n",
        "</div>\n",
        "\n",
        "Upon running this notebook, a new folder gets created in your Drive. You define the name of this folder and it will store all the data generated via this notebook.\n",
        "\n",
        "<div align=\"left\">\n",
        "  <h3> üìñ Reference Materials </h3>\n",
        "</div>\n",
        "\n",
        "This notebook takes inspiration from these resources:\n",
        "\n",
        "- [CD4+ T-cell Epitope Prediction Using Antigen Processing Constraints](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5321161/#SD1)\n",
        "- [Highly accurate protein structure prediction with AlphaFold](https://doi.org/10.1038/s41586-021-03819-2)\n",
        "\n",
        "<div align=\"left\">\n",
        "  <h3> üåê Legal & Data Formats </h3>\n",
        "</div>\n",
        "\n",
        "The provided code operates under the [Apache 2.0 license](https://www.apache.org/licenses/LICENSE-2.0). The license of the [structural prediction model parameters](https://github.com/deepmind/alphafold/#model-parameters-license) is Creative Commons Attribution 4.0 International ([CC BY 4.0](https://creativecommons.org/licenses/by/4.0/legalcode)).\n",
        "For details regarding the PAE file format, consult the [AFDB FAQ](https://alphafold.ebi.ac.uk/faq/#faq-7)."
      ],
      "metadata": {
        "id": "t3Dw-vO9DtPz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start by loading your data"
      ],
      "metadata": {
        "id": "3O2qMwNXuvwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install biopython --q\n",
        "import os, requests\n",
        "import pandas as pd\n",
        "from Bio.PDB import PDBParser, PPBuilder\n",
        "import warnings\n",
        "from Bio import BiopythonWarning"
      ],
      "metadata": {
        "id": "BFmTRwrrbw2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58a17f4b-405c-4850-b331-0b0bd596d036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/3.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.1/3.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.7/3.1 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set Up Google Drive\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "%pip install biopython --q\n",
        "import os, requests\n",
        "import pandas as pd\n",
        "from Bio.PDB import PDBParser, PPBuilder\n",
        "import warnings\n",
        "from Bio import BiopythonWarning\n",
        "\n",
        "class DataSheet:\n",
        "    def __init__(self):\n",
        "        self.dframe = pd.read_csv(os.path.join(project_dir, 'files', 'DataSheet.csv'), index_col='ID').drop(\"Unnamed: 0\", axis=1)[['Antigen/Gene', 'PDB ID']]\n",
        "        self.ids = [pdb_id for pdb_id in self.dframe['PDB ID'] if len(pdb_id) == 4]\n",
        "        self.dframe = self.dframe[self.dframe['PDB ID'].isin(self.ids)]\n",
        "        self.dframe['pdb path'] = None  # Add new column 'path' with default None\n",
        "        self.load()\n",
        "\n",
        "    def load(self):\n",
        "        parser = PDBParser()\n",
        "        ppb = PPBuilder()\n",
        "        for pdb_id in self.ids:\n",
        "            pdb_path = os.path.join(\"/content/drive/MyDrive/EpiFold2/\", \"files\", \"pdb files\", f\"{pdb_id}.pdb\")\n",
        "            if not os.path.exists(pdb_path):\n",
        "                response = requests.get(f\"https://files.rcsb.org/download/{pdb_id}.pdb\")\n",
        "                if response.status_code == 200:\n",
        "                    pdb_path = os.path.join(\"/content/drive/MyDrive/EpiFold2/\", \"files\", \"pdb files\", f\"{pdb_id}.pdb\")\n",
        "                    if not os.path.exists(os.path.join(\"/content/drive/MyDrive/EpiFold2/\", \"files\", \"pdb files\")):\n",
        "                      os.mkdir(os.path.join(\"/content/drive/MyDrive/EpiFold2/\", \"files\", \"pdb files\"))\n",
        "                    with open(pdb_path, 'wb') as f:\n",
        "                        f.write(response.content)\n",
        "                else:\n",
        "                    self.dframe.drop(self.dframe['PDB ID'] == pdb_id, axis=0)\n",
        "            self.dframe.loc[self.dframe['PDB ID'] == pdb_id, 'pdb path'] = pdb_path\n",
        "\n",
        "            fasta_sequence = self.extract_sequence(parser, ppb, pdb_path)\n",
        "            self.dframe.loc[self.dframe['PDB ID'] == pdb_id, 'FastA'] = str(fasta_sequence)\n",
        "        self.dframe = self.dframe.reset_index(drop=True)\n",
        "\n",
        "    def extract_sequence(self, parser, ppb, pdb_file_path):\n",
        "        structure = parser.get_structure('pdb', pdb_file_path)\n",
        "        for pp in ppb.build_peptides(structure):\n",
        "            return pp.get_sequence()\n",
        "\n",
        "def custom_warning(message, category, filename, lineno, file=None, line=None):\n",
        "    if \"Chain\" in str(message) and \"is discontinuous\" in str(message):\n",
        "        return\n",
        "    else:\n",
        "        warnings.showwarning(message, category, filename, lineno, file, line)\n",
        "warnings.showwarning = custom_warning\n",
        "\n",
        "project_name = input('I want to save my project results in my google drive in a folder called ')\n",
        "project_dir = f'/content/drive/MyDrive/{project_name}'\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "if not os.path.exists(project_dir):\n",
        "    os.mkdir(project_dir)\n",
        "    os.mkdir(os.path.join(project_dir, 'files'))\n",
        "print(\"\\nPlease save you datasheet as DataSheet.csv\")\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "import shutil\n",
        "current_colab_dir = f'/content/drive/MyDrive/{project_name}.ipynb'\n",
        "source_dir = '/content/DatasetSheet.csv'\n",
        "target_dir = f'/content/drive/MyDrive/{project_name}/files/DataSheet.csv'\n",
        "shutil.move(source_dir, target_dir)\n",
        "datasheet = DataSheet()\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "df = datasheet.dframe\n",
        "df[['PDB ID', 'FastA']]\n",
        "\n",
        "\n",
        "def write_fasta(filename, sequence):\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(\">protein\\n\")\n",
        "        f.write(sequence)\n",
        "\n",
        "fasta_files_dir = \"/content/drive/MyDrive/EpiFold2/files/fasta files\"\n",
        "os.makedirs(fasta_files_dir, exist_ok=True)  # Creates the directory if it doesn't already exist\n",
        "\n",
        "for pdb_id, seq in zip(df['PDB ID'], df['FastA']):\n",
        "    write_fasta(os.path.join(fasta_files_dir, f\"{pdb_id}.fasta\"), seq)\n",
        "\n",
        "\n",
        "input_dir = fasta_files_dir\n",
        "result_dir = \"/content/drive/MyDrive/EpiFold2/files/results\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "CI-rUEXxL424",
        "outputId": "e672683d-a900-4e45-88d5-317b9876c6fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n%pip install biopython --q\\nimport os, requests\\nimport pandas as pd\\nfrom Bio.PDB import PDBParser, PPBuilder\\nimport warnings\\nfrom Bio import BiopythonWarning\\n\\nclass DataSheet:\\n    def __init__(self):\\n        self.dframe = pd.read_csv(os.path.join(project_dir, \\'files\\', \\'DataSheet.csv\\'), index_col=\\'ID\\').drop(\"Unnamed: 0\", axis=1)[[\\'Antigen/Gene\\', \\'PDB ID\\']]\\n        self.ids = [pdb_id for pdb_id in self.dframe[\\'PDB ID\\'] if len(pdb_id) == 4]\\n        self.dframe = self.dframe[self.dframe[\\'PDB ID\\'].isin(self.ids)]\\n        self.dframe[\\'pdb path\\'] = None  # Add new column \\'path\\' with default None\\n        self.load()\\n\\n    def load(self):\\n        parser = PDBParser()\\n        ppb = PPBuilder()\\n        for pdb_id in self.ids:\\n            pdb_path = os.path.join(\"/content/drive/MyDrive/EpiFold2/\", \"files\", \"pdb files\", f\"{pdb_id}.pdb\")\\n            if not os.path.exists(pdb_path):\\n                response = requests.get(f\"https://files.rcsb.org/download/{pdb_id}.pdb\")\\n                if response.status_code == 200:\\n                    pdb_path = os.path.join(\"/content/drive/MyDrive/EpiFold2/\", \"files\", \"pdb files\", f\"{pdb_id}.pdb\")\\n                    if not os.path.exists(os.path.join(\"/content/drive/MyDrive/EpiFold2/\", \"files\", \"pdb files\")):\\n                      os.mkdir(os.path.join(\"/content/drive/MyDrive/EpiFold2/\", \"files\", \"pdb files\"))\\n                    with open(pdb_path, \\'wb\\') as f:\\n                        f.write(response.content)\\n                else:\\n                    self.dframe.drop(self.dframe[\\'PDB ID\\'] == pdb_id, axis=0)\\n            self.dframe.loc[self.dframe[\\'PDB ID\\'] == pdb_id, \\'pdb path\\'] = pdb_path\\n\\n            fasta_sequence = self.extract_sequence(parser, ppb, pdb_path)\\n            self.dframe.loc[self.dframe[\\'PDB ID\\'] == pdb_id, \\'FastA\\'] = str(fasta_sequence)\\n        self.dframe = self.dframe.reset_index(drop=True)\\n\\n    def extract_sequence(self, parser, ppb, pdb_file_path):\\n        structure = parser.get_structure(\\'pdb\\', pdb_file_path)\\n        for pp in ppb.build_peptides(structure):\\n            return pp.get_sequence()\\n\\ndef custom_warning(message, category, filename, lineno, file=None, line=None):\\n    if \"Chain\" in str(message) and \"is discontinuous\" in str(message):\\n        return\\n    else:\\n        warnings.showwarning(message, category, filename, lineno, file, line)\\nwarnings.showwarning = custom_warning\\n\\nproject_name = input(\\'I want to save my project results in my google drive in a folder called \\')\\nproject_dir = f\\'/content/drive/MyDrive/{project_name}\\'\\n\\nfrom google.colab import drive\\ndrive.mount(\\'/content/drive\\', force_remount=True)\\n\\nif not os.path.exists(project_dir):\\n    os.mkdir(project_dir)\\n    os.mkdir(os.path.join(project_dir, \\'files\\'))\\nprint(\"\\nPlease save you datasheet as DataSheet.csv\")\\nfrom google.colab import files\\nfiles.upload()\\nimport shutil\\ncurrent_colab_dir = f\\'/content/drive/MyDrive/{project_name}.ipynb\\'\\nsource_dir = \\'/content/DatasetSheet.csv\\'\\ntarget_dir = f\\'/content/drive/MyDrive/{project_name}/files/DataSheet.csv\\'\\nshutil.move(source_dir, target_dir)\\ndatasheet = DataSheet()\\n\\n\\n#-------------------------------------------------------------------------------------------------------------\\n\\ndf = datasheet.dframe\\ndf[[\\'PDB ID\\', \\'FastA\\']]\\n\\n\\ndef write_fasta(filename, sequence):\\n    with open(filename, \\'w\\') as f:\\n        f.write(\">protein\\n\")\\n        f.write(sequence)\\n\\nfasta_files_dir = \"/content/drive/MyDrive/EpiFold2/files/fasta files\"\\nos.makedirs(fasta_files_dir, exist_ok=True)  # Creates the directory if it doesn\\'t already exist\\n\\nfor pdb_id, seq in zip(df[\\'PDB ID\\'], df[\\'FastA\\']):\\n    write_fasta(os.path.join(fasta_files_dir, f\"{pdb_id}.fasta\"), seq)\\n\\n\\ninput_dir = fasta_files_dir\\nresult_dir = \"/content/drive/MyDrive/EpiFold2/files/results\"\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install AlphaFold2\n",
        "\n",
        "%%bash -s $use_amber $use_templates $python_version\n",
        "\n",
        "set -e\n",
        "\n",
        "USE_AMBER=$1\n",
        "USE_TEMPLATES=$2\n",
        "PYTHON_VERSION=$3\n",
        "\n",
        "if [ ! -f COLABFOLD_READY ]; then\n",
        "  # install dependencies\n",
        "  # We have to use \"--no-warn-conflicts\" because colab already has a lot preinstalled with requirements different to ours\n",
        "  pip install -q --no-warn-conflicts \"colabfold[alphafold-minus-jax] @ git+https://github.com/sokrypton/ColabFold\" \"tensorflow-cpu==2.11.0\"\n",
        "  pip uninstall -yq jax jaxlib\n",
        "  pip install -q \"jax[cuda]==0.3.25\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "  touch COLABFOLD_READY\n",
        "fi\n",
        "\n",
        "# Download params (~1min)\n",
        "python -m colabfold.download\n",
        "\n",
        "# setup conda\n",
        "if [ ${USE_AMBER} == \"True\" ] || [ ${USE_TEMPLATES} == \"True\" ]; then\n",
        "  if [ ! -f CONDA_READY ]; then\n",
        "    wget -qnc https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "    bash Miniconda3-latest-Linux-x86_64.sh -bfp /usr/local 2>&1 1>/dev/null\n",
        "    rm Miniconda3-latest-Linux-x86_64.sh\n",
        "    conda config --set auto_update_conda false\n",
        "    touch CONDA_READY\n",
        "  fi\n",
        "fi\n",
        "# setup template search\n",
        "if [ ${USE_TEMPLATES} == \"True\" ] && [ ! -f HH_READY ]; then\n",
        "  conda install -y -q -c conda-forge -c bioconda kalign2=2.04 hhsuite=3.3.0 python=\"${PYTHON_VERSION}\" 2>&1 1>/dev/null\n",
        "  touch HH_READY\n",
        "fi\n",
        "# setup openmm for amber refinement\n",
        "if [ ${USE_AMBER} == \"True\" ] && [ ! -f AMBER_READY ]; then\n",
        "  conda install -y -q -c conda-forge openmm=7.7.0 python=\"${PYTHON_VERSION}\" pdbfixer 2>&1 1>/dev/null\n",
        "  touch AMBER_READY\n",
        "fi\n"
      ],
      "metadata": {
        "id": "RMBRC0rUMx-7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "outputId": "64ab76e5-8c9f-4f17-944a-e89a85d8a472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n%%bash -s $use_amber $use_templates $python_version\\n\\nset -e\\n\\nUSE_AMBER=$1\\nUSE_TEMPLATES=$2\\nPYTHON_VERSION=$3\\n\\nif [ ! -f COLABFOLD_READY ]; then\\n  # install dependencies\\n  # We have to use \"--no-warn-conflicts\" because colab already has a lot preinstalled with requirements different to ours\\n  pip install -q --no-warn-conflicts \"colabfold[alphafold-minus-jax] @ git+https://github.com/sokrypton/ColabFold\" \"tensorflow-cpu==2.11.0\"\\n  pip uninstall -yq jax jaxlib\\n  pip install -q \"jax[cuda]==0.3.25\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\\n  touch COLABFOLD_READY\\nfi\\n\\n# Download params (~1min)\\npython -m colabfold.download\\n\\n# setup conda\\nif [ ${USE_AMBER} == \"True\" ] || [ ${USE_TEMPLATES} == \"True\" ]; then\\n  if [ ! -f CONDA_READY ]; then\\n    wget -qnc https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\\n    bash Miniconda3-latest-Linux-x86_64.sh -bfp /usr/local 2>&1 1>/dev/null\\n    rm Miniconda3-latest-Linux-x86_64.sh\\n    conda config --set auto_update_conda false\\n    touch CONDA_READY\\n  fi\\nfi\\n# setup template search\\nif [ ${USE_TEMPLATES} == \"True\" ] && [ ! -f HH_READY ]; then\\n  conda install -y -q -c conda-forge -c bioconda kalign2=2.04 hhsuite=3.3.0 python=\"${PYTHON_VERSION}\" 2>&1 1>/dev/null\\n  touch HH_READY\\nfi\\n# setup openmm for amber refinement\\nif [ ${USE_AMBER} == \"True\" ] && [ ! -f AMBER_READY ]; then\\n  conda install -y -q -c conda-forge openmm=7.7.0 python=\"${PYTHON_VERSION}\" pdbfixer 2>&1 1>/dev/null\\n  touch AMBER_READY\\nfi\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUYApPElB30u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "outputId": "f1c8fd4e-6d5a-4b01-810f-d9bffa3db6eb"
      },
      "source": [
        "#@title Get AlphaFold2 Structures\n",
        "import sys\n",
        "\n",
        "from colabfold.batch import get_queries, run\n",
        "from colabfold.download import default_data_dir\n",
        "from colabfold.utils import setup_logging\n",
        "from pathlib import Path\n",
        "\n",
        "# For some reason we need that to get pdbfixer to import\n",
        "if False and f\"/usr/local/lib/python{python_version}/site-packages/\" not in sys.path:\n",
        "    sys.path.insert(0, f\"/usr/local/lib/python{python_version}/site-packages/\")\n",
        "\n",
        "if 'logging_setup' not in globals():\n",
        "    setup_logging(Path(result_dir).joinpath(\"log.txt\"))\n",
        "    logging_setup = True\n",
        "\n",
        "queries, is_complex = get_queries(input_dir)\n",
        "run(queries=queries,\n",
        "    result_dir=result_dir,\n",
        "    use_templates=False,\n",
        "    use_amber=False,\n",
        "    msa_mode=\"MMseqs2 (UniRef+Environmental)\",\n",
        "    model_type=\"auto\",\n",
        "    num_models=2,\n",
        "    num_recycles=3,\n",
        "    model_order=[1, 2],\n",
        "    is_complex=is_complex,\n",
        "    data_dir=default_data_dir,\n",
        "    keep_existing_results=True,\n",
        "    rank_by=\"auto\",\n",
        "    pair_mode=\"unpaired+paired\",\n",
        "    stop_at_score=98,\n",
        "    zip_results=True,\n",
        "    user_agent=\"colabfold/google-colab-batch\",)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom colabfold.batch import get_queries, run\\nfrom colabfold.download import default_data_dir\\nfrom colabfold.utils import setup_logging\\nfrom pathlib import Path\\n\\n# For some reason we need that to get pdbfixer to import\\nif False and f\"/usr/local/lib/python{python_version}/site-packages/\" not in sys.path:\\n    sys.path.insert(0, f\"/usr/local/lib/python{python_version}/site-packages/\")\\n\\nif \\'logging_setup\\' not in globals():\\n    setup_logging(Path(result_dir).joinpath(\"log.txt\"))\\n    logging_setup = True\\n\\nqueries, is_complex = get_queries(input_dir)\\nrun(queries=queries,\\n    result_dir=result_dir,\\n    use_templates=False,\\n    use_amber=False,\\n    msa_mode=\"MMseqs2 (UniRef+Environmental)\",\\n    model_type=\"auto\",\\n    num_models=2,\\n    num_recycles=3,\\n    model_order=[1, 2],\\n    is_complex=is_complex,\\n    data_dir=default_data_dir,\\n    keep_existing_results=True,\\n    rank_by=\"auto\",\\n    pair_mode=\"unpaired+paired\",\\n    stop_at_score=98,\\n    zip_results=True,\\n    user_agent=\"colabfold/google-colab-batch\",)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "!pwd\n",
        "\n",
        "def extract_best_pdb(zip_path, target_dir):\n",
        "    pdb_id = os.path.basename(zip_path).split(\".\")[0]\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        # Extract the specific rank_001.pdb file\n",
        "        for file in zip_ref.namelist():\n",
        "            if \"rank_001\" in file and file.endswith(\".pdb\"):\n",
        "                zip_ref.extract(file)\n",
        "                # Copy the file to the target directory\n",
        "                shutil.copy(file, os.path.join(target_dir, file))\n",
        "\n",
        "def rename_files_in_folder(folder_path, prefix=\"AF-\"):\n",
        "    files = os.listdir(folder_path)\n",
        "    for file_name in files:\n",
        "        if file_name.endswith(\".pdb\"):\n",
        "            old_file_path = os.path.join(folder_path, file_name)\n",
        "            new_file_name = f\"{prefix}{file_name.split('_')[0]}.pdb\"\n",
        "            new_file_path = os.path.join(folder_path, new_file_name)\n",
        "            os.rename(old_file_path, new_file_path)\n",
        "\n",
        "\n",
        "results_dir = '/content/drive/MyDrive/EpiFold2/files/results/'\n",
        "target_dir = '/content/drive/MyDrive/EpiFold2/files/AlphaFoldStructures/'\n",
        "\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "zip_paths = [os.path.join(results_dir, i) for i in os.listdir(results_dir) if '.zip' in i]\n",
        "for zip_path in zip_paths:\n",
        "    extract_best_pdb(zip_path, target_dir)\n",
        "\n",
        "rename_files_in_folder(target_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "yjoSTBJU44ud",
        "outputId": "7f6f15ef-29aa-4add-ae0e-0b406fccfea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport os\\nimport zipfile\\nimport shutil\\n!pwd\\n\\ndef extract_best_pdb(zip_path, target_dir):\\n    pdb_id = os.path.basename(zip_path).split(\".\")[0]\\n    with zipfile.ZipFile(zip_path, \\'r\\') as zip_ref:\\n        # Extract the specific rank_001.pdb file\\n        for file in zip_ref.namelist():\\n            if \"rank_001\" in file and file.endswith(\".pdb\"):\\n                zip_ref.extract(file)\\n                # Copy the file to the target directory\\n                shutil.copy(file, os.path.join(target_dir, file))\\n\\ndef rename_files_in_folder(folder_path, prefix=\"AF-\"):\\n    files = os.listdir(folder_path)\\n    for file_name in files:\\n        if file_name.endswith(\".pdb\"):\\n            old_file_path = os.path.join(folder_path, file_name)\\n            new_file_name = f\"{prefix}{file_name.split(\\'_\\')[0]}.pdb\"\\n            new_file_path = os.path.join(folder_path, new_file_name)\\n            os.rename(old_file_path, new_file_path)\\n\\n\\nresults_dir = \\'/content/drive/MyDrive/EpiFold2/files/results/\\'\\ntarget_dir = \\'/content/drive/MyDrive/EpiFold2/files/AlphaFoldStructures/\\'\\n\\nos.makedirs(target_dir, exist_ok=True)\\n\\nzip_paths = [os.path.join(results_dir, i) for i in os.listdir(results_dir) if \\'.zip\\' in i]\\nfor zip_path in zip_paths:\\n    extract_best_pdb(zip_path, target_dir)\\n\\nrename_files_in_folder(target_dir)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "RicOBcCY7FaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict Epitopes"
      ],
      "metadata": {
        "id": "VR99eUFUuyR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Stability Profile Comparison: Experimental v.s. AlphaFold2"
      ],
      "metadata": {
        "id": "tjRU4w8RNShK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "FJVlnmshdN8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "8bf559eb-e82e-438a-864f-45efa17b085f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-91874b305a32>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    190\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not be a symlink'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not already contain files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must either be a directory or not exist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mountpoint must not already contain files"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install mdanalysis\n",
        "#!pip install mdbenchmark\n",
        "!pip install biobb_gromacs\n",
        "!pip install py3Dmol"
      ],
      "metadata": {
        "id": "FINYHXtF2rr8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "963f80d3-f506-42c3-d7f1-6ed097851619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biobb_gromacs\n",
            "  Downloading biobb_gromacs-4.1.1-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting biobb-common==4.1.0 (from biobb_gromacs)\n",
            "  Downloading biobb_common-4.1.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from biobb-common==4.1.0->biobb_gromacs) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from biobb-common==4.1.0->biobb_gromacs) (2.31.0)\n",
            "Requirement already satisfied: biopython in /usr/local/lib/python3.10/dist-packages (from biobb-common==4.1.0->biobb_gromacs) (1.81)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython->biobb-common==4.1.0->biobb_gromacs) (1.23.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->biobb-common==4.1.0->biobb_gromacs) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->biobb-common==4.1.0->biobb_gromacs) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->biobb-common==4.1.0->biobb_gromacs) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->biobb-common==4.1.0->biobb_gromacs) (2023.7.22)\n",
            "Installing collected packages: biobb-common, biobb_gromacs\n",
            "Successfully installed biobb-common-4.1.0 biobb_gromacs-4.1.1\n",
            "Collecting py3Dmol\n",
            "  Downloading py3Dmol-2.0.4-py2.py3-none-any.whl (12 kB)\n",
            "Installing collected packages: py3Dmol\n",
            "Successfully installed py3Dmol-2.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import MDAnalysis as md\n",
        "#import mdbenchmark\n",
        "import biobb_gromacs as bg\n",
        "import py3Dmol\n",
        "from zipfile import ZipFile\n",
        "from io import BytesIO\n",
        "#!pwd"
      ],
      "metadata": {
        "id": "ivMDIk5d1yIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#source cite for code: https://william-dawson.github.io/using-py3dmol.html\n",
        "\n",
        "with open('/content/drive/MyDrive/EpiFold2/files/pdb files/1AOL.pdb') as pfile:\n",
        "  system = \"\".join([x for x in pfile])\n",
        "\n",
        "view = py3Dmol.view(width=400, height=300)\n",
        "view.addModelsAsFrames(system)\n",
        "view.setStyle({'model': -1}, {\"cartoon\": {'color': 'spectrum'}})\n",
        "view.zoomTo()\n",
        "view.show()\n",
        "print('1AOL original pdb')"
      ],
      "metadata": {
        "id": "sULznFwy4SXq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "a6159677-39b6-4570-d4d8-e54f828c8208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f49f6c009740>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#source cite for code: https://william-dawson.github.io/using-py3dmol.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/EpiFold2/files/pdb files/1AOL.pdb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0msystem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpfile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/EpiFold2/files/pdb files/1AOL.pdb'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zipfilepath = '/content/drive/MyDrive/EpiFold2/files/results/1AOL.result.zip'\n",
        "fileiwant = '1AOL_unrelaxed_rank_001_alphafold2_ptm_model_2_seed_000.pdb'\n",
        "maybe_othercomf = '1AOL_unrelaxed_rank_002_alphafold2_ptm_model_1_seed_000.pdb'\n",
        "\n",
        "\n",
        "\n",
        "with ZipFile(zipfilepath, 'r') as z:\n",
        "    if fileiwant in z.namelist():\n",
        "        with z.open(fileiwant) as f:\n",
        "            content = \"\".join([x.decode('utf-8') for x in f])\n",
        "\n",
        "view = py3Dmol.view(width=400, height=300)\n",
        "view.addModelsAsFrames(content)\n",
        "view.setStyle({'model': -1}, {\"cartoon\": {'color': 'spectrum'}})\n",
        "view.zoomTo()\n",
        "view.show()\n",
        "print('1AOL alphafold best model')"
      ],
      "metadata": {
        "id": "RuGNt_O0fxLK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "1ca8e48a-e228-4ac8-858e-a44588ef386a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-eee2d9d475fb>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfileiwant\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileiwant\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/EpiFold2/files/results/1AOL.result.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing md simulation possibilities"
      ],
      "metadata": {
        "id": "8QezT039mJpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nglview\n",
        "!pip install mdanalysis\n",
        "!pip install openmm"
      ],
      "metadata": {
        "id": "vf59xtFJiq4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from simtk.open#mm.app import *\n",
        "#from simtk.openmm import *\n",
        "#from simtk.unit import *\n",
        "import MDAnalysis as md\n",
        "import nglview as ng\n",
        "from sys import stdout"
      ],
      "metadata": {
        "id": "rf-jZS3imeLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "b9uxlBiHnZhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#with open('/content/drive/MyDrive/EpiFold2/files/pdb files/1AOL.pdb') as pfile:\n",
        "#  system = \"\".join([x for x in pfile])\n",
        "\n",
        "pdbog = '/content/drive/MyDrive/EpiFold2/files/pdb files/1AOL.pdb'\n",
        "print('md simulat for 1AOL orig')\n",
        "v = md.Universe(pdbog)\n",
        "ng.show_mdanalysis(v, gui=True)\n"
      ],
      "metadata": {
        "id": "wYFf_aj2nb7w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "85088ad0-3441-4668-b089-db0fefd323b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "md simulat for 1AOL orig\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-77b96a6bef2b>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpdbog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/EpiFold2/files/pdb files/1AOL.pdb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'md simulat for 1AOL orig'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUniverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdbog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_mdanalysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgui\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'md' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original = '/content/drive/MyDrive/EpiFold2/files/pdb files/1AOL.pdb'\n",
        "with open(original) as f:\n",
        "  q = f.read()\n",
        "print(q)"
      ],
      "metadata": {
        "id": "QHtpe86s7_hI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "5cf33d1f-67b7-44ce-b17e-9581eec37c4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-c7d06ddf2506>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/EpiFold2/files/pdb files/1AOL.pdb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/EpiFold2/files/pdb files/1AOL.pdb'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import PDB\n",
        "\n",
        "\n",
        "zipfilepath = '/content/drive/MyDrive/EpiFold2/files/results/1AOL.result.zip'\n",
        "fileiwant = '1AOL_unrelaxed_rank_001_alphafold2_ptm_model_2_seed_000.pdb'\n",
        "\n",
        "with ZipFile(zipfilepath, 'r') as z:\n",
        "    if fileiwant in z.namelist():\n",
        "        with z.open(fileiwant) as f:\n",
        "          content = f.read()\n",
        "\n",
        "decode = content.decode('utf-8')\n",
        "print(decode)\n",
        "val = md.Universe(decode)\n",
        "ng.show_mdanalysis(val, gui=True)"
      ],
      "metadata": {
        "id": "DGiKt4dRqSaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edited_alpha = '/content/drive/MyDrive/edited_alphafold_1AOL.pdb'\n",
        "val = md.Universe(edited_alpha)\n",
        "ng.show_mdanalysis(val, gui=True)"
      ],
      "metadata": {
        "id": "LUAyzS-j-A8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "new = md.Universe(edited_alpha)\n",
        "ref = md.Universe(pdbog)\n",
        "#ref = MDAnalysis.Universe(PSF,CRD)    # reference open AdK (4AKE)\n",
        "\n",
        "import MDAnalysis.analysis.rms\n",
        "from MDAnalysis.analysis import rms\n",
        "from MDAnalysis.analysis import align\n",
        "\n",
        "u = md.Universe(new, ref, in_memory=True)\n",
        "protein = u.select_atoms(\"protein\")\n",
        "\n",
        "\n",
        "prealigner = align.AlignTraj(u, select=\"protein and name CA\", in_memory=True).run()\n",
        "\n",
        "# 3) reference = average structure\n",
        "reference_coordinates = u.trajectory.timeseries(asel=protein).mean(axis=1)\n",
        "# make a reference structure (need to reshape into a 1-frame \"trajectory\")\n",
        "reference = md.Merge(protein).load_new(\n",
        "            reference_coordinates[:, None, :], order=\"afc\")\n",
        "\n",
        "\n",
        "\n",
        "#common_residues = set(ref.residues) & set(u.residues)\n",
        "\n",
        "#common_atoms = ref.select_atoms(f\"resid {' '.join(str(res.id) for res in common_residues)}\")\n",
        "\n",
        "#rmsd_analysis = rms.RMSD(u, ref)\n",
        "#rmsd_analysis = rms.RMSD(common_residues)\n",
        "#rmsd_analysis.run()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Cu_ovSneWneV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support for third party widgets will remain active for the duration of the session. To disable support:"
      ],
      "metadata": {
        "id": "0JvNDMXpnZhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.disable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "-ef6BNFbnZhD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}